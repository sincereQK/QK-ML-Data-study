{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOEqCDzd1gF7oar3tinWYbj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sincereQK/QK-ML-Data-study/blob/main/stock_LSTM_20250908.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ZD42Cud0t4e"
      },
      "outputs": [],
      "source": [
        "# pip install tensorflow scikit-learn pandas numpy matplotlib pandas-ta"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade pandas-ta"
      ],
      "metadata": {
        "id": "T90qO4xI0xAd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install --upgrade pandas-ta\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pandas_ta as ta\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout, Input\n",
        "import os\n",
        "import glob\n",
        "from datetime import datetime, timedelta\n",
        "import sys\n",
        "\n",
        "# --- 1. CSV íŒŒì¼ ë™ì  ê²€ìƒ‰ ë° ë¶ˆëŸ¬ì˜¤ê¸° ---\n",
        "\n",
        "# ì‚¬ìš©í•  ë³€ìˆ˜ë“¤\n",
        "folder_path = 'CSV'\n",
        "company_name = 'ê²½ë°©'\n",
        "today_str = datetime.now().strftime('%Y%m%d')\n",
        "found_file = None\n",
        "\n",
        "# íŒŒì¼ ê²€ìƒ‰\n",
        "try:\n",
        "    # CSV í´ë”ê°€ ì—†ìœ¼ë©´ ì—ëŸ¬ ë°œìƒ\n",
        "    if not os.path.isdir(folder_path):\n",
        "        raise FileNotFoundError\n",
        "\n",
        "    for filename in os.listdir(folder_path):\n",
        "        # íŒŒì¼ëª…ì— ì˜¤ëŠ˜ ë‚ ì§œê°€ í¬í•¨ë˜ê³ , ì§€ì •ëœ íšŒì‚¬ ì´ë¦„ìœ¼ë¡œ ëë‚˜ëŠ”ì§€ í™•ì¸\n",
        "        if today_str in filename and filename.endswith(f'{company_name}.csv'):\n",
        "            found_file = os.path.join(folder_path, filename)\n",
        "            print(f\"íŒŒì¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤: {found_file}\")\n",
        "            break # íŒŒì¼ì„ ì°¾ìœ¼ë©´ ë°˜ë³µ ì¤‘ë‹¨\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"ì˜¤ë¥˜: '{folder_path}' í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.\")\n",
        "    sys.exit()\n",
        "\n",
        "# íŒŒì¼ì„ ì°¾ì§€ ëª»í–ˆìœ¼ë©´ í”„ë¡œê·¸ë¨ ì¢…ë£Œ\n",
        "if found_file is None:\n",
        "    print(f\"ì˜¤ë¥˜: '{folder_path}' í´ë”ì—ì„œ ì˜¤ëŠ˜ ë‚ ì§œ({today_str})ì™€ '{company_name}' ì´ë¦„ì´ í¬í•¨ëœ CSV íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "    sys.exit()\n",
        "\n",
        "# ì°¾ì€ íŒŒì¼ì„ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "df = pd.read_csv(found_file)\n",
        "\n",
        "\n",
        "# --- 2. ë°ì´í„° ì „ì²˜ë¦¬ ë° ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚° ---\n",
        "df['ì¼ì'] = pd.to_datetime(df['ì¼ì'], format='%Y%m%d')\n",
        "df = df.sort_values('ì¼ì').reset_index(drop=True)\n",
        "df['sma20'] = ta.sma(df['í˜„ì¬ê°€'], length=20)\n",
        "df['rsi14'] = ta.rsi(df['í˜„ì¬ê°€'], length=14)\n",
        "df.dropna(subset=['sma20', 'rsi14'], inplace=True)\n",
        "df = df.reset_index(drop=True)\n",
        "\n",
        "features = ['ì‹œê°€', 'ê³ ê°€', 'ì €ê°€', 'í˜„ì¬ê°€', 'ê±°ë˜ëŸ‰', 'sma20', 'rsi14']\n",
        "data = df[features].copy()\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaled_data = scaler.fit_transform(data)\n",
        "\n",
        "# --- 3. ëª¨ë¸ íŒŒì¼ ê´€ë¦¬ ë° í•™ìŠµ/ë¶ˆëŸ¬ì˜¤ê¸° ë¡œì§ ---\n",
        "# company_name ë³€ìˆ˜ëŠ” ì´ë¯¸ ìœ„ì—ì„œ ì •ì˜ë˜ì—ˆìœ¼ë¯€ë¡œ ê·¸ëŒ€ë¡œ ì‚¬ìš©\n",
        "today_str = datetime.now().strftime('%Y%m%d')\n",
        "model_filename = f'model_{company_name}_{today_str}.keras'\n",
        "should_train_new_model = True\n",
        "\n",
        "existing_models = glob.glob(f'model_{company_name}_*.keras')\n",
        "\n",
        "if existing_models:\n",
        "    latest_model_file = max(existing_models, key=os.path.getctime)\n",
        "    print(f\"ê°€ì¥ ìµœì‹  ëª¨ë¸ íŒŒì¼: '{latest_model_file}'\")\n",
        "\n",
        "    try:\n",
        "        model_date_str = latest_model_file.split('_')[-1].replace('.keras', '')\n",
        "        model_date = datetime.strptime(model_date_str, '%Y%m%d')\n",
        "\n",
        "        if datetime.now() - model_date < timedelta(days=7):\n",
        "            print(\"ìµœì‹  ëª¨ë¸ì´ 7ì¼ ì´ë‚´ì— í•™ìŠµë˜ì—ˆìŠµë‹ˆë‹¤. ê¸°ì¡´ ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.\")\n",
        "            model = load_model(latest_model_file)\n",
        "            should_train_new_model = False\n",
        "        else:\n",
        "            print(\"ìµœì‹  ëª¨ë¸ì´ 7ì¼ ì´ìƒ ê²½ê³¼ë˜ì—ˆìŠµë‹ˆë‹¤. ìƒˆë¡œìš´ í•™ìŠµì´ í•„ìš”í•©ë‹ˆë‹¤.\")\n",
        "    except (ValueError, IndexError):\n",
        "        print(\"ëª¨ë¸ íŒŒì¼ëª…ì—ì„œ ë‚ ì§œë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ìƒˆë¡œìš´ í•™ìŠµì„ ì§„í–‰í•©ë‹ˆë‹¤.\")\n",
        "\n",
        "if should_train_new_model:\n",
        "    if not existing_models:\n",
        "        print(\"ì €ì¥ëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. ìƒˆë¡œ ëª¨ë¸ì„ í•™ìŠµí•˜ê³  ì €ì¥í•©ë‹ˆë‹¤.\")\n",
        "\n",
        "    train_data_len = int(np.ceil(len(scaled_data) * 0.8))\n",
        "    train_data = scaled_data[0:train_data_len, :]\n",
        "    x_train, y_train = [], []\n",
        "    look_back = 60\n",
        "\n",
        "    for i in range(look_back, len(train_data)):\n",
        "        x_train.append(train_data[i-look_back:i, :])\n",
        "        y_train.append(train_data[i, 3])\n",
        "\n",
        "    x_train, y_train = np.array(x_train), np.array(y_train)\n",
        "\n",
        "    model = Sequential([\n",
        "        Input(shape=(x_train.shape[1], x_train.shape[2])),\n",
        "        LSTM(units=50, return_sequences=True),\n",
        "        Dropout(0.2),\n",
        "        LSTM(units=50, return_sequences=False),\n",
        "        Dropout(0.2),\n",
        "        Dense(units=25),\n",
        "        Dense(units=1)\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "    model.fit(x_train, y_train, batch_size=32, epochs=50, verbose=1)\n",
        "\n",
        "    print(f\"ìƒˆë¡œ í•™ìŠµëœ ëª¨ë¸ì„ '{model_filename}' íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.\")\n",
        "    model.save(model_filename)\n",
        "\n",
        "# --- 4. ë‹¤ìŒ ë‚  ì£¼ê°€ ì˜ˆì¸¡ ---\n",
        "look_back = 60\n",
        "last_look_back_days_scaled = scaled_data[-look_back:]\n",
        "x_predict = np.reshape(last_look_back_days_scaled, (1, look_back, len(features)))\n",
        "predicted_price_scaled = model.predict(x_predict)\n",
        "\n",
        "dummy_predict = np.zeros((1, len(features)))\n",
        "dummy_predict[:, 3] = predicted_price_scaled\n",
        "predicted_price = scaler.inverse_transform(dummy_predict)[:, 3][0]\n",
        "\n",
        "# --- 5. ë§¤ë§¤ ì‹ í˜¸ íŒë‹¨ ---\n",
        "latest_data = df.iloc[-1]\n",
        "current_price = latest_data['í˜„ì¬ê°€']\n",
        "current_sma20 = latest_data['sma20']\n",
        "current_rsi14 = latest_data['rsi14']\n",
        "\n",
        "print(\"\\n--- ë§¤ë§¤ ì‹ í˜¸ íŒë‹¨ ---\")\n",
        "print(f\"í˜„ì¬ ê°€ê²©: {current_price:,.0f}ì›\")\n",
        "print(f\"ë‹¤ìŒ ë‚  ì˜ˆì¸¡ ê°€ê²©: {predicted_price:,.0f}ì›\")\n",
        "print(f\"í˜„ì¬ 20ì¼ ì´ë™í‰ê· ì„ : {current_sma20:,.0f}ì›\")\n",
        "print(f\"í˜„ì¬ RSI14: {current_rsi14:.2f}\")\n",
        "print(\"--------------------\")\n",
        "\n",
        "def get_trading_signal(predicted, current, sma20, rsi14):\n",
        "    is_buy_signal = (predicted > current * 1.02 and current > sma20 and rsi14 < 70)\n",
        "    is_sell_signal = (predicted < current * 0.98)\n",
        "\n",
        "    if is_buy_signal:\n",
        "        print(\"íŒë‹¨: ğŸ“ ë§¤ìˆ˜ ì‹ í˜¸\")\n",
        "        return 1\n",
        "    elif is_sell_signal:\n",
        "        print(\"íŒë‹¨: ğŸ“‰ ë§¤ë„ ì‹ í˜¸\")\n",
        "        return 0\n",
        "    else:\n",
        "        print(\"íŒë‹¨: â˜• ê´€ë§ (ë§¤ë§¤ ì‹ í˜¸ ì—†ìŒ)\")\n",
        "        return None\n",
        "\n",
        "signal = get_trading_signal(predicted_price, current_price, current_sma20, current_rsi14)\n",
        "print(f\"\\nìµœì¢… ì¶œë ¥: {signal}\")"
      ],
      "metadata": {
        "id": "pAZb18l90yGb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
